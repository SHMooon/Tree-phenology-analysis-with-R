---
title: "SMoon_Logbook"
author: "Sang Hyo Moon"
date: "2023-11-13"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(chillR)
```

# Introduction 

# tools 

# tree dormancy 

## Exercises
### Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer.
### Which are the advantages (2) of the BBCH scale compared with earlies scales?
- Standardized across the world 
- More specific
### Classify the following phenological stages of sweet cherry according to the BBCH scale:Phenological stages of cherry

```{r, }
knitr::include_graphics('pictures/3-1.png')


```
- budding- 54
- flowering- 65
- fruiting- 87


# Climate change and impact projection
## Exercises on climate change

Please document all results of the following assignments in your learning logbook.

### List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate.
- Greenhouse Gas Emissions
- Aerosols and Particulate Matte
- Ozone Depletion
- Solar Variability

### Explain briefly what is special about temperature dynamics of recent decades, and why we have good reasons to be concerned.

### What does the abbreviation ‘RCP’ stand for, how are RCPs defined, and what is their role in projecting future climates?

### Briefly describe the 4 climate impact projection methods described in the fourth video.

# Winter chill projections
## Exercises on past chill projections

Please document all results of the following assignments in your learning logbook.

### Sketch out three data access and processing challenges that had to be overcome in order to produce chill projections with state-of-the-art methodology.
- equipment and infrastructure limitations for processing large amounts of data
- some locations lack high-resolution climate data sets, therefore estimations (with a margin of error) about neighboring locations having data available would need to be made
- form in which the data is available (particularly for very large data); raster data requires further processes to be rendered usable.


### Outline, in your understanding, the basic steps that are necessary to make such projections.
- 1. Understanding Context and System in a location 
- 2. Formulating Research Question
- 3. Selecting Climate Model and Projection Ensembles
- 4. Data Acquisition
- 5. Interpolating/Estimating Gaps
- 6. Data Processing with Chosen Model
- 7. Comparison with Existing Projections/Observations
- 8. Conclusion
- 9. Expression of Uncertainties and Errors

# Manual chill analysis
chilling period: end of dormancy 
## computing 

```{r include=FALSE}
library(chillR)
library(knitr)
library(pander)
library(kableExtra)
library(tidyverse)

```



## Exercises on basic chill modeling

Please document all results of the following assignments in your learning logbook.

### Write a basic function that calculates warm hours (>25°C)
```{r include=FALSE}
library(knitr)
library(pander)
library(kableExtra)
library(chillR)
```

```{r, eval=FALSE}
 

Year<-c(2000:2010)
Temps<-c(20:30)
randomdataset<-data.frame(Year, Temps)

##function creation, assigning of threshold to variable
WarmHours<- function(randomdataset)
    {
      threshold_warm<- 25
      randomdataset[,"Warm_year"]<- randomdataset$Temps>threshold_warm
      return(randomdataset)
 }

RandomWarmHours<-WarmHours(randomdataset)

write.csv(RandomWarmHours, "data/WarmHours.csv", row.names = FALSE)
```

```{r, echo=FALSE}

RandomWarmHours<-read_tab("data/WarmHours.csv")
WarmHours<-read_tab("data/WarmHours.csv")
kable(head(WarmHours)) %>%
kable_styling("striped", position = "center",font_size = 10)
```




### Apply this function to the Winters_hours_gaps dataset

```{r, eval=FALSE}

hourtemps<- Winters_hours_gaps[,c("Year", "Month", "Day", "Hour", "Temp")]

WarmHours2<- function(hourtemps)
    {
      threshold_warm<- 25
      hourtemps[,"Warm_Hour"]<- hourtemps$Temp>threshold_warm
      return(hourtemps)
    }

write.csv(WH(hourtemps),"data/WarmHours2.csv", row.names = FALSE)
```

```{r, echo=FALSE}
WarmHours2<-read_tab("data/WarmHours2.csv")
 kable(head(WarmHours2)) %>%
      kable_styling("striped", position = "left",font_size = 10)
```

### Extend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates




# Chill models
## Exercises on chill models

Please document all results of the following assignments in your learning logbook.

### Run the chilling() function on the Winters_hours_gap dataset
```{r, eval=FALSE}
library(chillR)
chill_7_1<-chilling(make_JDay(Winters_hours_gaps),Start_JDay = 90, End_JDay = 100)

write.csv(chill_7_1, "data/chill_7_1.csv", row.names = FALSE)
```

```{r,echo=FALSE}
chill_7_1<-read_tab("data/chill_7_1.csv")
kable(head(chill_7_1)) %>%
  kable_styling("striped", position = "left",font_size = 10)
```


### Create your own temperature-weighting chill model using the step_model() function


### Run this model on the Winters_hours_gaps dataset using the tempResponse() function.

# Making hourly temperatures
## Exercises on hourly temperatures

Please document all results of the following assignments in your learning logbook.

### Choose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength

```{r include=FALSE}
require(chillR)
require(ggplot2)
require(reshape2)

```


```{r}
Kiel_Days <- daylength(latitude = 54.32, JDay = 1:365)

Kiel_Days_df <-
  data.frame(
    JDay = 1:365,
    Sunrise = Kiel_Days$Sunrise,
    Sunset = Kiel_Days$Sunset,
    Daylength = Kiel_Days$Daylength
  )

Kiel_Days_df <- pivot_longer(Kiel_Days_df,cols=c(Sunrise:Daylength))

ggplot(Kiel_Days_df, aes(JDay, value)) +
  geom_line(lwd = 1.5) +
  facet_grid(cols = vars(name)) +
  ylab("Time of Day / Daylength (Hours)") +
  theme_bw(base_size = 20)

```


 location=c(10.139444, 54.323334),
                          time_interval=c(1990,2020))

### Produce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR)

```{r}
require(chillR)

 KA_weather_stacked <- stack_hourly_temps(KA_weather, latitude=54.32)

write.csv(KA_weather_stacked, "data/KA_weather_stacked.csv", row.names = FALSE)

```

```{r, echo=FALSE}
    require(kableExtra)

    KA_weather_stacked<-read_tab("data/KA_weather_stacked.csv")

    kable(head(KA_weather_stacked)) %>%
      kable_styling("striped", position = "left",font_size = 10)
    ```

### Produce empirical temperature curve parameters for the Winters_hours_gaps dataset, and use them to predict hourly values from daily temperatures (this is very similar to the example above, but please make sure you understand what’s going on)

```{r, eval=FALSE}
library(chillR)
library(ggplot2)

coeffs <- Empirical_daily_temperature_curve(Winters_hours_gaps)
Winters_daily <-
  make_all_day_table(Winters_hours_gaps, input_timestep = "hour")
Winters_hours <- Empirical_hourly_temperatures(Winters_daily, coeffs)


require(reshape2)

Winters_hours <- Winters_hours[, c("Year", "Month", "Day", "Hour", "Temp")]
colnames(Winters_hours)[ncol(Winters_hours)] <- "Temp_empirical"
Winters_ideal <-
  stack_hourly_temps(Winters_daily, latitude = 38.5)$hourtemps
Winters_ideal <- Winters_ideal[, c("Year", "Month", "Day", "Hour", "Temp")]
colnames(Winters_ideal)[ncol(Winters_ideal)] <- "Temp_ideal"

```




#Some useful tools in R
## on useful R tools

Please document all results of the following assignments in your learning logbook.

### Based on the Winters_hours_gaps dataset, use magrittr pipes and functions of the tidyverse to accomplish the following:
- Convert the dataset into a tibble
- Select only the top 10 rows of the dataset
- Convert the tibble to a long format, with separate rows for Temp_gaps and Temp
- Use ggplot2 to plot Temp_gaps and Temp as facets (point or line plot)
- Convert the dataset back to the wide format
- Select only the following columns: Year, Month, Day and Temp
- Sort the dataset by the Temp column, in descending order
### For the Winter_hours_gaps dataset, write a for loop to convert all temperatures (Temp column) to degrees Fahrenheit
### Execute the same operation with a function from the apply family
### Now use the tidyverse function mutate to achieve the same outcome
### Voluntary: consider taking a look at the instruction materials on all these functions, which I linked above, as well as at other sources on the internet. There’s a lot more to discover here, with lots of potential for making your coding more elegant and easier - and possibly even more fun!



# Some useful tools in R 

## Exercises on useful R tools

Please document all results of the following assignments in your learning logbook.

### Based on the Winters_hours_gaps dataset, use magrittr pipes and functions of the tidyverse to accomplish the following:
- Convert the dataset into a tibble
- Select only the top 10 rows of the dataset
- Convert the tibble to a long format, with separate rows for Temp_gaps and Temp
- Use ggplot2 to plot Temp_gaps and Temp as facets (point or line plot)
- Convert the dataset back to the wide format
- Select only the following columns: Year, Month, Day and Temp
- Sort the dataset by the Temp column, in descending order
### For the Winter_hours_gaps dataset, write a for loop to convert all temperatures (Temp column) to degrees Fahrenheit
### Execute the same operation with a function from the apply family
### Now use the tidyverse function mutate to achieve the same outcome
### Voluntary: consider taking a look at the instruction materials on all these functions, which I linked above, as well as at other sources on the internet. There’s a lot more to discover here, with lots of potential for making your coding more elegant and easier - and possibly even more fun!


# Getting temperature data


## Exercises on getting temperature data

Please document all results of the following assignments in your learning logbook.

### Choose a location of interest and find the 25 closest weather stations using the handle_gsod function
- Kiel 

```{r echo=TRUE}
Kiel_list<-handle_gsod(action="list_stations",
                          location=c(10.28, 54.5),
                          time_interval=c(1990,2020))

require(kableExtra)

kable(Kiel_list) %>%
  kable_styling("striped", position = "left", font_size = 8)

```
### Download weather data for the most promising station on the list
```{r}

weather_Kiel<-handle_gsod(action="download_weather",
                     location=Kiel_list$chillR_code[9],
                     time_interval=c(1990,2020))
```

```{r}
weather_Kiel[[1]][1:20,]

```


### Convert the weather data into chillR format
 
```{r}
cleaned_weather_Kiel<-handle_gsod(weather_Kiel)
cleaned_weather_Kiel[[1]][1:20,]
```


```{r}

write.csv(Kiel_list,"data/Kiel_station_list.csv",row.names=FALSE)
write.csv(weather_Kiel[[1]],"data/Kiel_raw_weather.csv",row.names=FALSE)
write.csv(cleaned_weather_Kiel[[1]],"data/Kiel_chillR_weather.csv",row.names=FALSE)
```




# Filling gaps in temperature records

## Gaps

## Exercises on filling gaps

Please document all results of the following assignments in your learning logbook.

You already downloaded some weather data in the exercises for the Getting temperatures lesson. You can keep working with this.
```{r}
#from previous data
Kiel<-read.csv("data/Kiel_chillR_weather.csv")
```



### Use chillR functions to find out how many gaps you have in this dataset (even if you have none, please still follow all further steps)

```{r}

#checking for gaps using fix_weather function
Kiel_QC<-fix_weather(Kiel)$QC
write.csv(Kiel_QC, "data/Kiel_QC.csv", row.names = FALSE)


```

```{r}

##saving and downloading the needed columns
Kiel_weather<-Kiel[,c("Year","Month", "Day", "Tmax", "Tmin")]
kable(Kiel_weather,) %>%
  kable_styling("striped", position = "left", font_size = 10)

write.csv(Kiel_weather, "data/Kiel_weather.csv", row.names = FALSE)
```


```{r, echo=FALSE}
    Kiel_QC<-read_tab("data/Kiel_QC.csv")

    kable(head(Kiel_QC), caption="Quality control summary produced by *fix_weather()*") %>%
      kable_styling("striped", position = "left", font_size = 10)
```


```{r, echo=FALSE}
    library(kableExtra)
    Kiel_weather<-read_tab("data/Kiel_weather.csv")

    kable(head(Kiel_weather)) %>%
      kable_styling("striped", position = "left", font_size = 10)
    ```


### Create a list of the 25 closest weather stations using the handle_gsod function

```{r}
Kiel_list<-handle_gsod(action="list_stations",
                          location=c(10.28, 54.5),
                          time_interval=c(1990,2020))

kable(Kiel_list) %>%
  kable_styling("striped", position = "left", font_size = 8)

```



### Identify suitable weather stations for patching gaps

I will work with the position 9,14 and 24. 



### Download weather data for promising stations, convert them to chillR format and compile them in a list

```{r}
Kiel_patch_weather<-
      handle_gsod(action = "download_weather",
                  location = as.character(Kiel_list$chillR_code[c(10,14,24)]),
                  time_interval = c(1990,2020)) %>%
  handle_gsod()


```

### Use the patch_daily_temperatures function to fill gaps

```{r}
Kiel_patched <- patch_daily_temperatures(weather = Kiel,
                                    patch_weather = Kiel_patch_weather)


save_temperature_scenarios(Kiel_patched,"data/", "Kiel_patched")

#Kiel_patched[[2]]

Kiel_patched$statistics[[1]]
Kiel_patched$statistics[[2]]
Kiel_patched$statistics[[3]]

```
the Data from all positions look good. 
So it is not necessary to cap the mean_bias at 1 °C and the stdev_bias at 2°C.
By the data from Schleswig, 44 gaps for Tmin and 57 gaps for Tmax were able to be filled. There were 10 gaps remain for Tmin and 14 gaps remain. By the Data from Meierwik,I was able to filled no gaps for Tmin and 57 gaps for Tmax. There were 54 gaps remain for Tmin and 14 for Tmax, respectively. By the data from Hohn, I was able to filled 42 gaps for Tmin and 1 for Tmax. There were 12 gaps remain for Tmin and 13 for Tmax.




### Investigate the results - have all gaps been filled?

```{r, eval=FALSE}
    library(chillR)

    patched<-read.csv("data/Kiel_patched_1_weather.csv")

    post_patch_stats<-fix_weather(patched)$QC

    write.csv(post_patch_stats, "data/Kiel_post_patchstats.csv", row.names = FALSE)
```

    ```{r, echo=FALSE}
    library(kableExtra)

    post_patch_stats<-read_tab("data/Kiel_post_patchstats.csv")

    kable(post_patch_stats,) %>%
      kable_styling("striped", position = "left", font_size = 10)
    ```
 
There are 5 days missing after the patching. It seems safe to use linear interpolation for such a short gap.



### If necessary, repeat until you have a dataset you can work with in further analyses

```{r}
Kiel_post_patch_stats <- fix_weather(Kiel_patched)$QC

Kiel_post_patch_stats

 write.csv(Kiel_post_patch_stats, "data/Kiel_post_patch_stats.csv", row.names = FALSE)

```

 

```{r}
Kiel_weather2<-fix_weather(Kiel_patched)

write.csv(Kiel_weather2$weather, "data/Kiel_patched2.csv", row.names = FALSE)

Kiel_weather<-Kiel_weather2$weather[c("Year","Month", "Day", "Tmin", "Tmax")]
kable(Kiel_weather,) %>%
  kable_styling("striped", position = "left", font_size = 10)

Kiel_weather <- round(Kiel_weather, digits = 1)

write.csv(Kiel_weather, "data/Kiel_weather.csv", row.names = FALSE)

```

# Generating temperature scenarios
- wather generator: random data (like a dice) from a virtual collection
- Risk assessment: 
- LARS-WG: not that easy to use 
- RMAWAGEN: little complicate, but after few day using, then it works good. 

if generator not work then we need to install old one. 
- How to use weather generator 

## Exercises on temperature generation

Please document all results of the following assignments in your learning logbook.

### For the location you chose for your earlier analyses, use chillR’s weather generator to produce 100 years of synthetic temperature data.

The location where I choose is c(10.28, 54.5) 

```{r include=FALSE}
library(chillR)
library(RMAWGEN)
library(ggplot2)
library(dplyr)

```


```{r echo=FALSE}
#from the fixed weather
Kiel_weather<-read.csv("data/Kiel_weather.csv")

Kiel_weather <- round(Kiel_weather, digits = 1)

Temp <- temperature_generation(Kiel_weather,
                         years=c(1998,2005),
                         sim_years = c(2001,2100))

Temperatures<-cbind(Kiel_weather[
       which(Kiel_weather$Year %in% 1998:2005),] ,Data_source="observed")
     
Temperatures<-rbind(Temperatures,
                         cbind(Temp[[1]][,c("Year","Month","Day","Tmin","Tmax")],
                               Data_source="simulated"))

Temperatures[,"Date"]<-as.Date(ISOdate(2000, Temperatures$Month, Temperatures$Day))

```



### Calculate winter chill (in Chill Portions) for your synthetic weather, and illustrate your results as histograms and cumulative distributions.

```{r, eval=FALSE}


     chill_observed<-chilling(
       stack_hourly_temps(
         Temperatures[which(Temperatures$Data_source=="observed"),],
         latitude = 54.5),
       Start_JDay = 305,
       End_JDay = 59)
     
     chill_simulated<-chilling(
       stack_hourly_temps(
         Temperatures[which(Temperatures$Data_source=="simulated"),],
         latitude = 54.5),
       Start_JDay = 305,
       End_JDay = 59)
     
     chill_comparison<-cbind(chill_observed ,Data_source="observed")
     chill_comparison<-rbind(chill_comparison,
                             cbind(chill_simulated ,Data_source="simulated"))
     
     chill_comparison_full_seasons<-chill_comparison[
       which(chill_comparison$Perc_complete==100),]

    ggplot(chill_comparison_full_seasons, aes(x=Chill_portions)) + 
      geom_histogram(binwidth=1,aes(fill = factor(Data_source))) +
      theme_bw(base_size = 20) +
      labs(fill = "Data source") +
      xlab("Chill accumulation (Chill Portions)") +
      ylab("Frequency")



    chill_simulations<-chill_comparison_full_seasons[
      which(chill_comparison_full_seasons$Data_source=="simulated"),]

    ggplot(chill_simulations, aes(x=Chill_portions)) +
      stat_ecdf(geom = "step",lwd=1.5,col="blue") +
      ylab("Cumulative probability") +
      xlab("Chill accumulation (in Chill Portions)") +
      theme_bw(base_size = 20)

    write.csv(chill_comparison_full_seasons,"data/chill_comparison_full_seasons.csv", row.names = FALSE)

    ```

    ```{r, echo=FALSE}
    library(knitr)
    library(kableExtra)
    chill_comparison_full_seasons<-read_tab("data/chill_comparison_full_seasons.csv")

    kable(head(chill_comparison_full_seasons)) %>%
      kable_styling("striped", position = "left", font_size = 10)
    ```

```{r, eval=FALSE}
    ##amount of chill that is exceeded in 90% of all years
    quantile(chill_simulations$Chill_portions, 0.1)
      #  10% 
    #59.0096 

    ##chill at 50% confidence interval (25th and 75th percentile)
    quantile(chill_simulations$Chill_portions, c(0.25,0.75))
       #  25%      75% 
    #62.81098 71.61968 
    ```

### Produce similar plots for the number of freezing hours (<0°C) in April (or October, if your site is in the Southern Hemisphere) for your location of interest.
check lecture 7 to change it.



# Saving and loading data (and hiding this in markdown)
## Exercises on saving and loading data

We don’t have to do any exercises on this, but make sure you apply this in your learning logbook. Otherwise the lessons of the next few sessions will make it very difficult to work with the markdown file.

# historic temperature scenarios
## Exercises on generating historic temperature scenarios

Please document all results of the following assignments in your learning logbook.

### For the location you chose for previous exercises, produce historic temperature scenarios representing several years of the historic record (your choice).

### Produce chill distributions for these scenarios and plot them.

# future temperature scenarios
## Exercises on generating future temperature scenarios

Please document all results of the following assignments in your learning logbook.

### Analyze the historic and future impact of climate change on three agroclimatic metrics of your choice, for the location you’ve chosen for your earlier analyses.


# future temperature scenarios

CMIP6: lastly updated
- they are came from  scenarios contained in the Special Report on Emission Scenarios (SRES) (2000): used not that much anymore 
- Representative Concentration Pathways (RCPs): currently recommended, technically used 
- Shared Socioeconomic Pathways (SSPs). (2021): Eike use this 



## Exercises on future temperature scenarios

Please document all results of the following assignments in your learning logbook.

### Briefly describe the differences between the RCPs and the SSPs (you may have to follow some of the links provided above). 
- briefly... 

# Making CMPI6 scenario

# Making CMPI5 scenario (we didn't do it)

# Plotting uture scenario 

# Chill model comparison

# Simple phenology analysis 

# Delineating temperature response phases with PLS regression

- PLS (projection to latent structures): the damage level is correlated with the reflection. 
- 21.3: correlation with a flowering. higher temp earlier blooming date. 
- approx method. 
- the dataset from defferent cultivars show the same patterns
- with datasets, we don't have to visit in orchard. but modeling... 
- Important: always keep in mind that we’re using PLS with a very small dataset and we should not place too much emphasis on individual characteristics of the emerging model coefficient patterns#

